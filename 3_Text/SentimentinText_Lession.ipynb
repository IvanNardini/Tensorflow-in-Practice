{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentinText_Lession.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN7POtsDfOfd",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37OCP7utB3_1",
        "colab_type": "text"
      },
      "source": [
        "## Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soJqUrzufZns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GCWEEz-fnLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = [\"Ivan's studying\", \"He's hungry\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8DXklWOf-pU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7b030ee-95af-4ef5-d2c1-0a7b90716687"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(test)  \n",
        "widx = tokenizer.word_index\n",
        "print(widx)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(test)\n",
        "\n",
        "print(sequences)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"ivan's\": 1, 'studying': 2, \"he's\": 3, 'hungry': 4}\n",
            "[[1, 2], [3, 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzBT610uByIS",
        "colab_type": "text"
      },
      "source": [
        "## Problem: New words outside training sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HPUwrQCB0fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fail = [\"Ivan's studying\", \"He's hungry\", \"He's tired\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdkJG0E0B_iU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84f8366f-e62e-4562-8610-dfb2c78e162c"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(fail)\n",
        "\n",
        "print(sequences)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2], [3, 4], [3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVMBCSMaEPiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4ae65180-0c27-4cea-b544-e99d83722ea5"
      },
      "source": [
        "# To avoid this problem...\n",
        "tokenizer = Tokenizer(num_words=100, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(fail)  \n",
        "widx = tokenizer.word_index\n",
        "print(widx)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(fail)\n",
        "\n",
        "print(sequences)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOV>': 1, \"he's\": 2, \"ivan's\": 3, 'studying': 4, 'hungry': 5, 'tired': 6}\n",
            "[[3, 4], [2, 5], [2, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpTopuGrE7Zc",
        "colab_type": "text"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NljNHngI3Oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4b722515-6609-4159-f1bd-6c168a2e5e19"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded = pad_sequences(sequences)\n",
        "print(padded)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3 4]\n",
            " [2 5]\n",
            " [2 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz15F_PnI8-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "763b993a-081b-4748-f2ee-5363089c2724"
      },
      "source": [
        "padded = pad_sequences(sequences,\n",
        "                       maxlen = 3, \n",
        "                       padding='post')\n",
        "print(padded)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3 4 0]\n",
            " [2 5 0]\n",
            " [2 6 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ruc0omXKLjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}